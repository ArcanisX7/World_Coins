{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "World Coins: A collection of coin images from 32 different currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seznam knihoven\n",
    "import os\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB3, MobileNetV3Large\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_efficientnet\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as preprocess_mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Napojení dat a vytvoření cesty\n",
    "data_dir_train = \"data/coins/data/train/\"\n",
    "data_dir_val = \"data/coins/data/validation/\"\n",
    "log_dir = \"models/training_logs/\"\n",
    "model_dir = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 100\n",
    "NUM_CLASSES = 211\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření složek, pokud neexistují\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6174 images belonging to 211 classes.\n",
      "Found 844 images belonging to 211 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator s odpovídajícím předzpracováním pro ResNet50\n",
    "train_datagen_resnet = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_resnet,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],  # Lehké změny jasu\n",
    "    channel_shift_range=20.0) # Malé změny barev\n",
    "\n",
    "val_datagen_resnet = ImageDataGenerator(preprocessing_function=preprocess_resnet)\n",
    "\n",
    "# Načtení datasetu\n",
    "train_generator_resnet = train_datagen_resnet.flow_from_directory(\n",
    "    data_dir_train,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator_resnet = val_datagen_resnet.flow_from_directory(\n",
    "    data_dir_val,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Nastavení steps_per_epoch\n",
    "steps_per_epoch = len(train_generator_resnet)\n",
    "validation_steps = max(len(val_generator_resnet), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Načtení předtrénovaného modelu ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Přidání nových vrstev\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)  # Přidána hlubší Dense vrstva\n",
    "x = BatchNormalization()(x)  # Normalizace pro stabilnější trénování\n",
    "x = Dropout(0.4)(x)  # Silnější regulace\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Vytvoření modelu\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Kompilace modelu\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(os.path.join(model_dir, \"best_ResNet50.keras\"), save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "log_file = os.path.join(log_dir, \"ResNet50.csv\")\n",
    "csv_logger = CSVLogger(log_file, append=True)\n",
    "\n",
    "# Trénování modelu\n",
    "history = model.fit(\n",
    "    train_generator_resnet,\n",
    "    validation_data=val_generator_resnet,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postupné rozmrznutí některých vrstev pro doladění\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Rekompilace\n",
    "model.compile(optimizer=Adam(learning_rate=3e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Další fáze trénování\n",
    "history_fine = model.fit(\n",
    "    train_generator_resnet,\n",
    "    validation_data=val_generator_resnet,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, csv_logger])\n",
    "\n",
    "# Uložení modelu\n",
    "best_model_path = os.path.join(model_dir, \"best_ResNet50.keras\")\n",
    "if os.path.exists(best_model_path):\n",
    "    model.save(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6174 images belonging to 211 classes.\n",
      "Found 844 images belonging to 211 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen_efficientnet = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_efficientnet,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    brightness_range=[0.9, 1.1])  # Lehké změny jasu\n",
    "\n",
    "val_datagen_efficientnet = ImageDataGenerator(preprocessing_function=preprocess_efficientnet)\n",
    "\n",
    "train_generator_efficientnet = train_datagen_efficientnet.flow_from_directory(\n",
    "    data_dir_train,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator_efficientnet = val_datagen_efficientnet.flow_from_directory(\n",
    "    data_dir_val,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Nastavení steps_per_epoch\n",
    "steps_per_epoch = len(train_generator_efficientnet)\n",
    "validation_steps = max(len(val_generator_efficientnet), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MilanPštross\\Documents\\Word_Coins\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 4s/step - accuracy: 0.0145 - loss: 5.3308 - val_accuracy: 0.0604 - val_loss: 5.1911 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 4s/step - accuracy: 0.0788 - loss: 5.0933 - val_accuracy: 0.1019 - val_loss: 4.9886 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.1340 - loss: 4.8257 - val_accuracy: 0.1363 - val_loss: 4.7258 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 4s/step - accuracy: 0.1714 - loss: 4.5265 - val_accuracy: 0.1789 - val_loss: 4.4215 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.2178 - loss: 4.2043 - val_accuracy: 0.2453 - val_loss: 4.1037 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 4s/step - accuracy: 0.2839 - loss: 3.8244 - val_accuracy: 0.3246 - val_loss: 3.7931 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 4s/step - accuracy: 0.3228 - loss: 3.5364 - val_accuracy: 0.3685 - val_loss: 3.5228 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 4s/step - accuracy: 0.3607 - loss: 3.2694 - val_accuracy: 0.4182 - val_loss: 3.2915 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 4s/step - accuracy: 0.3941 - loss: 3.0958 - val_accuracy: 0.4443 - val_loss: 3.1008 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 4s/step - accuracy: 0.4314 - loss: 2.8687 - val_accuracy: 0.4799 - val_loss: 2.9383 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 4s/step - accuracy: 0.4488 - loss: 2.7250 - val_accuracy: 0.4929 - val_loss: 2.8066 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 4s/step - accuracy: 0.4754 - loss: 2.5970 - val_accuracy: 0.5166 - val_loss: 2.6961 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 4s/step - accuracy: 0.4906 - loss: 2.4733 - val_accuracy: 0.5391 - val_loss: 2.5885 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 4s/step - accuracy: 0.5073 - loss: 2.3933 - val_accuracy: 0.5474 - val_loss: 2.5058 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 4s/step - accuracy: 0.5247 - loss: 2.2923 - val_accuracy: 0.5557 - val_loss: 2.4240 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4s/step - accuracy: 0.5263 - loss: 2.2461 - val_accuracy: 0.5723 - val_loss: 2.3504 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 4s/step - accuracy: 0.5446 - loss: 2.1510 - val_accuracy: 0.5758 - val_loss: 2.2910 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 4s/step - accuracy: 0.5572 - loss: 2.0559 - val_accuracy: 0.5865 - val_loss: 2.2317 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 4s/step - accuracy: 0.5670 - loss: 2.0162 - val_accuracy: 0.6007 - val_loss: 2.1656 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 4s/step - accuracy: 0.5902 - loss: 1.9400 - val_accuracy: 0.6007 - val_loss: 2.1218 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 4s/step - accuracy: 0.5898 - loss: 1.8970 - val_accuracy: 0.6173 - val_loss: 2.0788 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.6000 - loss: 1.8336 - val_accuracy: 0.6102 - val_loss: 2.0350 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.5951 - loss: 1.8549 - val_accuracy: 0.6197 - val_loss: 1.9993 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 4s/step - accuracy: 0.6152 - loss: 1.7834 - val_accuracy: 0.6291 - val_loss: 1.9553 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 4s/step - accuracy: 0.6232 - loss: 1.7259 - val_accuracy: 0.6315 - val_loss: 1.9219 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 4s/step - accuracy: 0.6431 - loss: 1.6438 - val_accuracy: 0.6434 - val_loss: 1.8856 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 4s/step - accuracy: 0.6283 - loss: 1.6414 - val_accuracy: 0.6410 - val_loss: 1.8518 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 4s/step - accuracy: 0.6566 - loss: 1.5687 - val_accuracy: 0.6410 - val_loss: 1.8238 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 4s/step - accuracy: 0.6613 - loss: 1.5708 - val_accuracy: 0.6469 - val_loss: 1.7951 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.6706 - loss: 1.4976 - val_accuracy: 0.6517 - val_loss: 1.7634 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 4s/step - accuracy: 0.6804 - loss: 1.4864 - val_accuracy: 0.6528 - val_loss: 1.7525 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 4s/step - accuracy: 0.6968 - loss: 1.4144 - val_accuracy: 0.6647 - val_loss: 1.7178 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.6792 - loss: 1.4502 - val_accuracy: 0.6682 - val_loss: 1.7002 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 4s/step - accuracy: 0.6834 - loss: 1.4282 - val_accuracy: 0.6647 - val_loss: 1.6764 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 4s/step - accuracy: 0.6952 - loss: 1.3787 - val_accuracy: 0.6647 - val_loss: 1.6488 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 4s/step - accuracy: 0.6919 - loss: 1.3580 - val_accuracy: 0.6671 - val_loss: 1.6339 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 4s/step - accuracy: 0.7135 - loss: 1.2989 - val_accuracy: 0.6789 - val_loss: 1.6156 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 4s/step - accuracy: 0.7071 - loss: 1.3239 - val_accuracy: 0.6742 - val_loss: 1.6037 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 4s/step - accuracy: 0.7138 - loss: 1.2970 - val_accuracy: 0.6801 - val_loss: 1.5928 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 4s/step - accuracy: 0.7168 - loss: 1.2631 - val_accuracy: 0.6825 - val_loss: 1.5687 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 4s/step - accuracy: 0.7119 - loss: 1.2526 - val_accuracy: 0.6801 - val_loss: 1.5506 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 4s/step - accuracy: 0.7375 - loss: 1.2023 - val_accuracy: 0.6908 - val_loss: 1.5390 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 4s/step - accuracy: 0.7306 - loss: 1.2129 - val_accuracy: 0.6908 - val_loss: 1.5227 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 4s/step - accuracy: 0.7324 - loss: 1.1733 - val_accuracy: 0.6943 - val_loss: 1.5073 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 4s/step - accuracy: 0.7365 - loss: 1.1712 - val_accuracy: 0.6955 - val_loss: 1.4965 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 4s/step - accuracy: 0.7559 - loss: 1.1059 - val_accuracy: 0.6848 - val_loss: 1.4843 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 5s/step - accuracy: 0.7441 - loss: 1.1391 - val_accuracy: 0.6967 - val_loss: 1.4666 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 5s/step - accuracy: 0.7423 - loss: 1.1209 - val_accuracy: 0.6908 - val_loss: 1.4597 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 4s/step - accuracy: 0.7549 - loss: 1.0940 - val_accuracy: 0.6991 - val_loss: 1.4498 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 4s/step - accuracy: 0.7470 - loss: 1.0861 - val_accuracy: 0.7062 - val_loss: 1.4267 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.7565 - loss: 1.0765 - val_accuracy: 0.7073 - val_loss: 1.4183 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 4s/step - accuracy: 0.7507 - loss: 1.0431 - val_accuracy: 0.7085 - val_loss: 1.4051 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.7599 - loss: 1.0328 - val_accuracy: 0.7156 - val_loss: 1.3982 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 4s/step - accuracy: 0.7689 - loss: 1.0152 - val_accuracy: 0.7227 - val_loss: 1.3888 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 4s/step - accuracy: 0.7605 - loss: 1.0091 - val_accuracy: 0.7180 - val_loss: 1.3791 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 4s/step - accuracy: 0.7696 - loss: 0.9834 - val_accuracy: 0.7133 - val_loss: 1.3683 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 5s/step - accuracy: 0.7852 - loss: 0.9812 - val_accuracy: 0.7156 - val_loss: 1.3609 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 4s/step - accuracy: 0.7854 - loss: 0.9509 - val_accuracy: 0.7133 - val_loss: 1.3544 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.7738 - loss: 0.9645 - val_accuracy: 0.7180 - val_loss: 1.3480 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 4s/step - accuracy: 0.7794 - loss: 0.9490 - val_accuracy: 0.7156 - val_loss: 1.3398 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 4s/step - accuracy: 0.7780 - loss: 0.9537 - val_accuracy: 0.7216 - val_loss: 1.3281 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 4s/step - accuracy: 0.7903 - loss: 0.8954 - val_accuracy: 0.7180 - val_loss: 1.3195 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 4s/step - accuracy: 0.7875 - loss: 0.9029 - val_accuracy: 0.7239 - val_loss: 1.3137 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 4s/step - accuracy: 0.7875 - loss: 0.8895 - val_accuracy: 0.7310 - val_loss: 1.2972 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 4s/step - accuracy: 0.7976 - loss: 0.8593 - val_accuracy: 0.7287 - val_loss: 1.2892 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4s/step - accuracy: 0.8052 - loss: 0.8539 - val_accuracy: 0.7334 - val_loss: 1.2821 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 4s/step - accuracy: 0.7960 - loss: 0.8735 - val_accuracy: 0.7310 - val_loss: 1.2817 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 4s/step - accuracy: 0.8030 - loss: 0.8292 - val_accuracy: 0.7334 - val_loss: 1.2789 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 4s/step - accuracy: 0.8112 - loss: 0.8224 - val_accuracy: 0.7417 - val_loss: 1.2661 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 4s/step - accuracy: 0.8234 - loss: 0.7912 - val_accuracy: 0.7334 - val_loss: 1.2661 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 4s/step - accuracy: 0.8046 - loss: 0.8167 - val_accuracy: 0.7405 - val_loss: 1.2591 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 4s/step - accuracy: 0.8006 - loss: 0.8223 - val_accuracy: 0.7382 - val_loss: 1.2519 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.8144 - loss: 0.7650 - val_accuracy: 0.7370 - val_loss: 1.2572 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 4s/step - accuracy: 0.8225 - loss: 0.7574 - val_accuracy: 0.7405 - val_loss: 1.2453 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.8080 - loss: 0.7945 - val_accuracy: 0.7429 - val_loss: 1.2297 - learning_rate: 1.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 4s/step - accuracy: 0.8186 - loss: 0.7647 - val_accuracy: 0.7429 - val_loss: 1.2307 - learning_rate: 1.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 4s/step - accuracy: 0.8131 - loss: 0.7699 - val_accuracy: 0.7512 - val_loss: 1.2228 - learning_rate: 1.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 4s/step - accuracy: 0.8271 - loss: 0.7429 - val_accuracy: 0.7405 - val_loss: 1.2191 - learning_rate: 1.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 4s/step - accuracy: 0.8323 - loss: 0.7317 - val_accuracy: 0.7429 - val_loss: 1.2098 - learning_rate: 1.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 4s/step - accuracy: 0.8309 - loss: 0.7213 - val_accuracy: 0.7476 - val_loss: 1.2102 - learning_rate: 1.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 5s/step - accuracy: 0.8232 - loss: 0.7342 - val_accuracy: 0.7441 - val_loss: 1.2026 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 4s/step - accuracy: 0.8250 - loss: 0.7216 - val_accuracy: 0.7512 - val_loss: 1.2011 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 4s/step - accuracy: 0.8277 - loss: 0.7061 - val_accuracy: 0.7500 - val_loss: 1.1975 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 4s/step - accuracy: 0.8435 - loss: 0.6610 - val_accuracy: 0.7488 - val_loss: 1.1939 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 4s/step - accuracy: 0.8480 - loss: 0.6678 - val_accuracy: 0.7488 - val_loss: 1.1849 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 4s/step - accuracy: 0.8327 - loss: 0.6825 - val_accuracy: 0.7547 - val_loss: 1.1770 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 4s/step - accuracy: 0.8353 - loss: 0.6790 - val_accuracy: 0.7547 - val_loss: 1.1797 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 4s/step - accuracy: 0.8420 - loss: 0.6587 - val_accuracy: 0.7500 - val_loss: 1.1755 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 4s/step - accuracy: 0.8418 - loss: 0.6496 - val_accuracy: 0.7571 - val_loss: 1.1707 - learning_rate: 1.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 4s/step - accuracy: 0.8406 - loss: 0.6707 - val_accuracy: 0.7488 - val_loss: 1.1651 - learning_rate: 1.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.8476 - loss: 0.6524 - val_accuracy: 0.7524 - val_loss: 1.1635 - learning_rate: 1.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 4s/step - accuracy: 0.8383 - loss: 0.6458 - val_accuracy: 0.7559 - val_loss: 1.1584 - learning_rate: 1.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.8630 - loss: 0.5955 - val_accuracy: 0.7512 - val_loss: 1.1529 - learning_rate: 1.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 4s/step - accuracy: 0.8425 - loss: 0.6380 - val_accuracy: 0.7536 - val_loss: 1.1512 - learning_rate: 1.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.8462 - loss: 0.6158 - val_accuracy: 0.7571 - val_loss: 1.1454 - learning_rate: 1.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.8578 - loss: 0.6091 - val_accuracy: 0.7524 - val_loss: 1.1443 - learning_rate: 1.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.8507 - loss: 0.6039 - val_accuracy: 0.7524 - val_loss: 1.1456 - learning_rate: 1.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.8475 - loss: 0.6172 - val_accuracy: 0.7547 - val_loss: 1.1352 - learning_rate: 1.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 4s/step - accuracy: 0.8540 - loss: 0.6009 - val_accuracy: 0.7536 - val_loss: 1.1292 - learning_rate: 1.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 4s/step - accuracy: 0.8595 - loss: 0.5871 - val_accuracy: 0.7547 - val_loss: 1.1340 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Načtení předtrénovaného modelu EfficientNetB3\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Zmrazení základního modelu\n",
    "\n",
    "# Přidání nových vrstev\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='swish')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Vytvoření modelu\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Kompilace modelu\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(os.path.join(model_dir, \"best_EfficientNetB3.keras\"), save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "log_file = os.path.join(log_dir, \"EfficientNetB3.csv\")\n",
    "csv_logger = CSVLogger(log_file, append=True)\n",
    "\n",
    "# Trénování modelu\n",
    "history = model.fit(\n",
    "    train_generator_efficientnet,\n",
    "    validation_data=val_generator_efficientnet,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postupné rozmrznutí některých vrstev pro doladění\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Rekompilace s nižší learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "\n",
    "# Další fáze trénování\n",
    "history_fine = model.fit(\n",
    "    train_generator_efficientnet,\n",
    "    validation_data=val_generator_efficientnet,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, csv_logger])\n",
    "\n",
    "# Uložení modelu\n",
    "best_model_path = os.path.join(model_dir, \"bbest_EfficientNetB3.keras\")\n",
    "if os.path.exists(best_model_path):\n",
    "    model.save(best_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model MobileNetV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6174 images belonging to 211 classes.\n",
      "Found 844 images belonging to 211 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen_mobilenet = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_mobilenet,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    brightness_range=[0.95, 1.05],  # Lehké změny jasu\n",
    "    channel_shift_range=10.0) # Malé změny barev\n",
    "\n",
    "val_datagen_mobilenet = ImageDataGenerator(preprocessing_function=preprocess_mobilenet)\n",
    "\n",
    "train_generator_mobilenet = train_datagen_mobilenet.flow_from_directory(\n",
    "    data_dir_train,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator_mobilenet = val_datagen_mobilenet.flow_from_directory(\n",
    "    data_dir_val,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Nastavení steps_per_epoch\n",
    "steps_per_epoch = len(train_generator_mobilenet)\n",
    "validation_steps = max(len(val_generator_mobilenet), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Načtení předtrénovaného modelu MobileNetV3\n",
    "base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Zmrazení základního modelu\n",
    "\n",
    "# Přidání vlastních vrstev\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(256, activation='hard_swish')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Vytvoření modelu\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Kompilace modelu\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(os.path.join(model_dir, \"best_MobileNetV3.keras\"), save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "log_file = os.path.join(log_dir, \"MobileNetV3_log.csv\")\n",
    "csv_logger = CSVLogger(log_file, append=True)\n",
    "\n",
    "# Trénování modelu\n",
    "history = model.fit(\n",
    "    train_generator_mobilenet,\n",
    "    validation_data=val_generator_mobilenet,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postupné rozmrznutí některých vrstev pro doladění\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:200]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Rekompilace s nižší learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Další fáze trénování\n",
    "history_fine = model.fit(\n",
    "    train_generator_mobilenet,\n",
    "    validation_data=val_generator_mobilenet,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, csv_logger])\n",
    "\n",
    "# Uložení modelu\n",
    "best_model_path = os.path.join(model_dir, \"best_MobileNetV3.keras\")\n",
    "if os.path.exists(best_model_path):\n",
    "    model.save(best_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
